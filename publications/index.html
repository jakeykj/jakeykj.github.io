<!DOCTYPE html>
<html lang="en">
  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <!-- Metadata, OpenGraph and Schema.org -->




<!-- Standard metadata -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<title>
  
  
    
      Publications | Kejing Yin
    
  
</title>
<meta name="author" content="Kejing Yin">
<meta name="description" content="* denotes equal contribution, &lt;sup&gt;&lt;i class='fa-regular fa-envelope'&gt;&lt;/i&gt;&lt;/sup&gt; denotes corresponding author.">










<!-- Bootstrap & MDB -->
<link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04">
<!-- <link rel="stylesheet" href="/assets/css/mdb.min.css?62a43d1430ddb46fc4886f9d0e3b49b8"> -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

<!-- Bootstrap Table -->


<!-- Fonts & Icons -->
<link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5">
<link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap">

<!-- Code Syntax Highlighting -->
<link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light">



<!-- Styles -->

  <link rel="shortcut icon" href="/assets/img/icon.png?531b2d2a7d53660b2615580d07113bef">

<link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e">
<link rel="canonical" href="https://kejing.me//publications/">

<!-- Dark Mode -->

  <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark">
  <script src="/assets/js/theme.js?0afe9f0ae161375728f7bcc5eb5b4ab4"></script>


<!-- GeoJSON support via Leaflet -->


<!-- diff2html -->






  </head>

  <!-- Body -->
  <body class="fixed-top-nav sticky-bottom-footer">
    <!-- Header -->
    <header>
  <!-- Nav Bar -->
  <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation">
    <div class="container">
      
        <a class="navbar-brand title font-weight-lighter" href="/">
          Kejing Yin
        </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>

      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          

          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">About
              
            </a>
          </li>

          <!-- Other pages -->
          
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
              
                <li class="nav-item active">
                  
                  <a class="nav-link" href="/publications/">Publications
                    
                      <span class="sr-only">(current)</span>
                    
                  </a>
                </li>
              
            
          
            
              
                <li class="nav-item ">
                  
                  <a class="nav-link" href="/services/">Services
                    
                  </a>
                </li>
              
            
          
            
              
                <li class="nav-item ">
                  
                  <a class="nav-link" href="/teaching/">Teaching
                    
                  </a>
                </li>
              
            
          
            
              
                <li class="nav-item ">
                  
                  <a class="nav-link" href="/openings/">Openings
                    
                  </a>
                </li>
              
            
          
          
            <!-- Toogle theme mode -->
            <li class="toggle-container">
              <button id="light-toggle" title="Change theme">
                <i class="fa-solid fa-moon"></i>
                <i class="fa-solid fa-sun"></i>
              </button>
            </li>
          
        </ul>
      </div>
    </div>
  </nav>
  
    <!-- Scrolling Progress Bar -->
    <progress id="progress" value="0">
      <div class="progress-container">
        <span class="progress-bar"></span>
      </div>
    </progress>
  
</header>


    <!-- Content -->
    <div class="container mt-5" role="main">
      
        <div class="post">
  <header class="post-header">
    <h1 class="post-title">Publications</h1>
    <p class="post-description">* denotes equal contribution, <sup><i class="fa-regular fa-envelope"></i></sup> denotes corresponding author.</p>
  </header>

  <article>
    <!-- _pages/publications.md -->
<div class="publications">

<h2 class="bibliography">2025</h2>
<ol class="bibliography">
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100">NeurIPS-25</abbr>
        
      
      
    </div>
  

  <!-- Entry bib key -->
  <div id="liu2025dipro" class="col-sm-8">

    <!-- Title -->
<div class="title">Multimodal Disease Progression Modeling via Spatiotemporal Disentanglement and Multiscale Alignment</div>
<!-- Author -->
<div class="author">
  

  
  

  

    Chen
        Liu, 

    Wenfang
        Yao, 

    <strong>Kejing
        Yin</strong><sup><i class="fa-regular fa-envelope"></i></sup>, 

    William K.
        Cheung, 

    and Jing
        Qin
</div>

<!-- Journal/Book title and date -->







<div class="periodical">
  <em>In Advances in Neural Information Processing Systems (NeurIPS-25)</em> ,  2025
</div>


    
    
      <div class="periodical" style="color:Gray ; font-size: 0.9rem; margin-bottom: 0;">
        <i class="fa-regular fa-hand-point-right"></i> Spotlight: top 3.55% among 21,575 submissions
      </div>
    

    <!-- Publication Badges -->
    
      
      
      
      
      
    

    <!-- Links/Buttons -->
    <div class="links">
    
    <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
    
    
    
    
    
    
    
    
</div>

  
    <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p>Longitudinal multimodal data, including electronic health records (EHR) and sequential chest X-rays (CXRs), is critical for modeling disease progression, yet remains underutilized due to two key challenges: (1) redundancy in consecutive CXR sequences, where static anatomical regions dominate over clinically-meaningful dynamics, and (2) temporal misalignment between sparse, irregular imaging and continuous EHR data. We introduce DiPro, a novel framework that addresses these challenges through region-aware disentanglement and multi-timescale alignment. First, we disentangle static (anatomy) and dynamic (pathology progression) features in sequential CXRs, prioritizing disease-relevant changes. Second, we hierarchically align these static and dynamic CXR features with asynchronous EHR data via local (pairwise interval-level) and global (full-sequence) synchronization to model coherent progression pathways. Extensive experiments on the MIMIC dataset demonstrate that DiPro could effectively extract temporal clinical dynamics and achieve state-of-the-art performance on both disease progression identification and general ICU prediction tasks.</p>
    </div>
  

  
    <!-- Hidden bibtex block -->
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">liu2025dipro</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Liu, Chen and Yao, Wenfang and Yin, Kejing and Cheung, William K. and Qin, Jing}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Advances in Neural Information Processing Systems (NeurIPS-25)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Multimodal Disease Progression Modeling via Spatiotemporal Disentanglement and Multiscale Alignment}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
    </div>
  

  



  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100">NeurIPS-25</abbr>
        
      
      
    </div>
  

  <!-- Entry bib key -->
  <div id="wang2025curv" class="col-sm-8">

    <!-- Title -->
<div class="title">CURV: Coherent Uncertainty-Aware Reasoning in Vision-Language Models for X-Ray Report Generation</div>
<!-- Author -->
<div class="author">
  

  
  

  

    Ziao
        Wang, 

    Sixing
        Yan, 

    <strong>Kejing
        Yin</strong><sup><i class="fa-regular fa-envelope"></i></sup>, 

    Xiaofeng
        Zhang, 

    and William K.
        Cheung
</div>

<!-- Journal/Book title and date -->







<div class="periodical">
  <em>In Advances in Neural Information Processing Systems (NeurIPS-25)</em> ,  2025
</div>


    
    

    <!-- Publication Badges -->
    
      
      
      
      
      
    

    <!-- Links/Buttons -->
    <div class="links">
    
    <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
    
    
    
    
    
    
    
    
</div>

  
    <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p>Vision-language models have been explored for radiology report generation with promising results. Yet, uncertainty elaborated in findings and the reasoning process for reaching clinical impressions are seldom explicitly modeled, reducing the clinical accuracy and trustworthiness of the generated reports. We present CURV, a novel framework that alleviates the limitations through integrated awareness of uncertainty and explicit reasoning capabilities. Our approach consists of three key components: (1) an uncertainty modeling mechanism that teaches the model to recognize and express appropriate levels of diagnostic confidence, (2) a structured reasoning framework that generates intermediate explanatory steps connecting visual findings to clinical impressions, and (3) a reasoning coherence reward that ensures logical consistency among findings, reasoning, and impressions. We implement CURV through a three-stage training pipeline that combines uncertainty-aware fine-tuning, reasoning initialization, and reinforcement learning. In particular, we adopt a comprehensive reward function addresses multiple aspects of report quality, incorporating medical term matching, uncertainty expression evaluation, and semantic coherence evaluation. Experimental results demonstrate that CURV generates clinically relevant reports with appropriate uncertainty expressions and transparent reasoning traces, significantly outperforming previous methods. CURV represents a substantial advancement toward interpretable and trustworthy AI-generated radiology reports, with broader implications for the deployment of vision-language models in high-stakes clinical environments where uncertainty awareness and reasoning transparency are essential.</p>
    </div>
  

  
    <!-- Hidden bibtex block -->
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">wang2025curv</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wang, Ziao and Yan, Sixing and Yin, Kejing and Zhang, Xiaofeng and Cheung, William K.}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Advances in Neural Information Processing Systems (NeurIPS-25)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{CURV: Coherent Uncertainty-Aware Reasoning in Vision-Language Models for X-Ray Report Generation}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
    </div>
  

  



  </div>
</div>
</li>
</ol>
<h2 class="bibliography">2024</h2>
<ol class="bibliography">
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100">NeurIPS-24</abbr>
        
      
      
        
          
          

<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/neurips24_ddlcxr-480.webp 480w,/assets/img/publication_preview/neurips24_ddlcxr-800.webp 800w,/assets/img/publication_preview/neurips24_ddlcxr-1400.webp 1400w," sizes="200px" type="image/webp"></source>
    
    <img src="/assets/img/publication_preview/neurips24_ddlcxr.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="neurips24_ddlcxr.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

  
</figure>

        
      
    </div>
  

  <!-- Entry bib key -->
  <div id="yao2024ddlcxr" class="col-sm-8">

    <!-- Title -->
<div class="title">Addressing Asynchronicity in Clinical Multimodal Fusion via Individualized Chest X-ray Generation</div>
<!-- Author -->
<div class="author">
  

  
  

  

    Wenfang
        Yao*, 

    Chen
        Liu*, 

    <strong>Kejing
        Yin</strong><sup><i class="fa-regular fa-envelope"></i></sup>, 

    William K.
        Cheung, 

    and Jing
        Qin
</div>

<!-- Journal/Book title and date -->







<div class="periodical">
  <em>In Advances in Neural Information Processing Systems (NeurIPS-24)</em> ,  2024
</div>


    
    

    <!-- Publication Badges -->
    
      
      
      
      
      
    

    <!-- Links/Buttons -->
    <div class="links">
    
    <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
    
        <a href="https://arxiv.org/pdf/2410.17918" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
    
    
    
    
    
    
    
    
    
    
</div>

  
    <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p>Integrating multi-modal clinical data, such as electronic health records (EHR) and chest X-ray images (CXR), is particularly beneficial for clinical prediction tasks. However, in a temporal setting, multi-modal data are often inherently asynchronous. EHR can be continuously collected but CXR is generally taken with a much longer interval due to its high cost and radiation dose. When clinical prediction is needed, the last available CXR image might have been outdated, leading to suboptimal predictions. To address this challenge, we propose DDL-CXR, a method that dynamically generates an up-to-date latent representation of the individualized CXR images. Our approach leverages latent diffusion models for patient-specific generation strategically conditioned on a previous CXR image and EHR time series, providing information regarding anatomical structures and disease progressions, respectively. In this way, the interaction across modalities could be better captured by the latent CXR generation process, ultimately improving the prediction performance. Experiments using MIMIC datasets show that the proposed model could effectively address asynchronicity in multimodal fusion and consistently outperform existing methods.</p>
    </div>
  

  
    <!-- Hidden bibtex block -->
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">yao2024ddlcxr</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yao, Wenfang and Liu, Chen and Yin, Kejing and Cheung, William K. and Qin, Jing}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Advances in Neural Information Processing Systems (NeurIPS-24)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Addressing Asynchronicity in Clinical Multimodal Fusion via Individualized Chest {X-ray} Generation}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
    </div>
  

  



  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100">IEEE CAI</abbr>
        
      
      
    </div>
  

  <!-- Entry bib key -->
  <div id="wu2024an" class="col-sm-8">

    <!-- Title -->
<div class="title">An End-to-end Learning Approach for Counterfactual Generation and Individual Treatment Effect Estimation</div>
<!-- Author -->
<div class="author">
  

  
  

  

    Feilong
        Wu, 

    <strong>Kejing
        Yin</strong>, 

    and William K.
        Cheung
</div>

<!-- Journal/Book title and date -->







<div class="periodical">
  <em>In 2024 IEEE Conference on Artificial Intelligence (CAI)</em> ,  2024
</div>


    
    

    <!-- Publication Badges -->
    
      
      
      
      
      
    

    <!-- Links/Buttons -->
    <div class="links">
    
    <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    <a href="https://ieeexplore.ieee.org/document/10605309" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Publisher</a>
    
    
    
        <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=10605309" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
    
    
    
    
    
    
    
    
    
    
</div>

  
    <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p>Estimating the causal effect due to an intervention is important for many applications, such as healthcare. Unobserved counterfactuals make unbiased treatment effect estimation non-trivial. Among existing approaches, counterfactual generation which augments observational data with generated pseudo counterfactuals has been found promising for reducing the bias. These methods typically take a two-stage approach for the counterfactual generation and treatment effect estimation. Therefore, the counterfactual generation could be sub-optimal. To this end, we propose to jointly optimize the auxiliary models for generating the counterfactuals and the outcome estimation models. In particular, we demonstrate the viability by first connecting a counterfactual outcome generator with a reparameterized VAE model, and then learning them in an end-to-end fashion using the EM algorithm. Our evaluation results based on synthetic and semi-synthetic datasets show that a simple causal effect VAE model learned together with the counterfactual outcome generator can outperform a number of SOTA models for treatment effect estimation.</p>
    </div>
  

  

  



  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100">AAAI-24</abbr>
        
      
      
        
          
          

<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/aaai24_drfuse-480.webp 480w,/assets/img/publication_preview/aaai24_drfuse-800.webp 800w,/assets/img/publication_preview/aaai24_drfuse-1400.webp 1400w," sizes="200px" type="image/webp"></source>
    
    <img src="/assets/img/publication_preview/aaai24_drfuse.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="aaai24_drfuse.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

  
</figure>

        
      
    </div>
  

  <!-- Entry bib key -->
  <div id="drfuse2024yao" class="col-sm-8">

    <!-- Title -->
<div class="title">DrFuse: Learning Disentangled Representation for Clinical Multi-Modal Fusion with Missing Modality and Modal Inconsistency</div>
<!-- Author -->
<div class="author">
  

  
  

  

    Wenfang
        Yao*, 

    <strong>Kejing
        Yin</strong>*, 

    William K.
        Cheung, 

    Jia
        Liu, 

    and Jing
        Qin
</div>

<!-- Journal/Book title and date -->







<div class="periodical">
  <em>In Proceedings of the AAAI Conference on Artificial Intelligence</em> ,  2024
</div>


    
    
      <div class="periodical" style="color:Gray ; font-size: 0.9rem; margin-bottom: 0;">
        <i class="fa-regular fa-hand-point-right"></i> Acceptance ratio: 2342⁄9862 = 23.75%
      </div>
    

    <!-- Publication Badges -->
    
      
      
      
      
      
    

    <!-- Links/Buttons -->
    <div class="links">
    
    <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    <a href="https://ojs.aaai.org/index.php/AAAI/article/view/29578" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Publisher</a>
    
    
    
        <a href="https://arxiv.org/pdf/2403.06197.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
    
    
    
    
    
    
    <a href="https://github.com/dorothy-yao/drfuse" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
    
    
    
    
    
</div>

  
    <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p>The combination of electronic health records (EHR) and medical images is crucial for clinicians in making diagnoses and forecasting prognoses. Strategically fusing these two data modalities has great potential to improve the accuracy of machine learning models in clinical prediction tasks. However, the asynchronous and complementary nature of EHR and medical images presents unique challenges. Missing modalities due to clinical and administrative factors are inevitable in practice, and the significance of each data modality varies depending on the patient and the prediction target, resulting in inconsistent predictions and suboptimal model performance. To address these challenges, we propose DrFuse to achieve effective clinical multi-modal fusion. It tackles the missing modality issue by disentangling the features shared across modalities and those unique within each modality. Furthermore, we address the modal inconsistency issue via a disease-wise attention layer that produces the patient- and disease-wise weighting for each modality to make the final prediction. We validate the proposed method using real-world large-scale datasets, MIMIC-IV and MIMIC-CXR. Experimental results show that the proposed method significantly outperforms the state-of-the-art models.</p>
    </div>
  

  
    <!-- Hidden bibtex block -->
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">drfuse2024yao</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1609/aaai.v38i15.29578}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{DrFuse}: Learning Disentangled Representation for Clinical Multi-Modal Fusion with Missing Modality and Modal Inconsistency}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yao, Wenfang and Yin, Kejing and Cheung, William K. and Liu, Jia and Qin, Jing}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the AAAI Conference on Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{38}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{15}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{16416-16424}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
    </div>
  

  



  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100">Nat. Comm.</abbr>
        
      
      
    </div>
  

  <!-- Entry bib key -->
  <div id="zhang2024exploring" class="col-sm-8">

    <!-- Title -->
<div class="title">Exploring high-quality microbial genomes by assembling short-reads with long-range connectivity</div>
<!-- Author -->
<div class="author">
  

  
  

  

    Zhenmiao
        Zhang, 

    Jin
        Xiao, 

    Hongbo
        Wang, 

    Chao
        Yang, 

    Yufen
        Huang, 

    Zhen
        Yue, 

    Yang
        Chen, 

    Lijuan
        Han, 

    <strong>Kejing
        Yin</strong>, 

    Aiping
        Lyu, 

    Xiaodong
        Fang, 

    and Lu
        Zhang
</div>

<!-- Journal/Book title and date -->







<div class="periodical">
  <em>Nature Communications</em>,  2024
</div>


    
    

    <!-- Publication Badges -->
    
      
      
      
      
      
    

    <!-- Links/Buttons -->
    <div class="links">
    
    <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    <a href="https://www.nature.com/articles/s41467-024-49060-z" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Publisher</a>
    
    
    
        <a href="https://www.nature.com/articles/s41467-024-49060-z.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
    
    
    
    
    
    
    
    
    
    
</div>

  
    <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p>Although long-read sequencing enables the generation of complete genomes for unculturable microbes, its high cost limits the widespread adoption of long-read sequencing in large-scale metagenomic studies. An alternative method is to assemble short-reads with long-range connectivity, which can be a cost-effective way to generate high-quality microbial genomes. Here, we develop Pangaea, a bioinformatic approach designed to enhance metagenome assembly using short-reads with long-range connectivity. Pangaea leverages connectivity derived from physical barcodes of linked-reads or virtual barcodes by aligning short-reads to long-reads. Pangaea utilizes a deep learning-based read binning algorithm to assemble co-barcoded reads exhibiting similar sequence contexts and abundances, thereby improving the assembly of high- and medium-abundance microbial genomes. Pangaea also leverages a multi-thresholding algorithm strategy to refine assembly for low-abundance microbes. We benchmark Pangaea on linked-reads and a combination of short- and long-reads from simulation data, mock communities and human gut metagenomes. Pangaea achieves significantly higher contig continuity as well as more near-complete metagenome-assembled genomes (NCMAGs) than the existing assemblers. Pangaea also generates three complete and circular NCMAGs on the human gut microbiomes.</p>
    </div>
  

  

  



  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100">GigaScience</abbr>
        
      
      
    </div>
  

  <!-- Entry bib key -->
  <div id="yang2024lrtk" class="col-sm-8">

    <!-- Title -->
<div class="title">LRTK: a platform agnostic toolkit for linked-read analysis of both human genome and metagenome</div>
<!-- Author -->
<div class="author">
  

  
  

  

    Chao
        Yang, 

    Zhenmiao
        Zhang, 

    Yufen
        Huang, 

    Xuefeng
        Xie, 

    Herui
        Liao, 

    Jin
        Xiao, 

    Werner Pieter
        Veldsman, 

    <strong>Kejing
        Yin</strong>, 

    Xiaodong
        Fang, 

    and Lu
        Zhang
</div>

<!-- Journal/Book title and date -->







<div class="periodical">
  <em>GigaScience</em>,  2024
</div>


    
    

    <!-- Publication Badges -->
    
      
      
      
      
      
    

    <!-- Links/Buttons -->
    <div class="links">
    
    
    
    
    
    
    
    
    
    
    
    
    
</div>

  

  

  



  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100">IEEE JBHI</abbr>
        
      
      
        
          
          

<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/jbhi24_dnat-480.webp 480w,/assets/img/publication_preview/jbhi24_dnat-800.webp 800w,/assets/img/publication_preview/jbhi24_dnat-1400.webp 1400w," sizes="200px" type="image/webp"></source>
    
    <img src="/assets/img/publication_preview/jbhi24_dnat.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="jbhi24_dnat.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

  
</figure>

        
      
    </div>
  

  <!-- Entry bib key -->
  <div id="huang2024dna" class="col-sm-8">

    <!-- Title -->
<div class="title">DNA-T: Deformable Neighborhood Attention Transformer for Irregular Medical Time Series</div>
<!-- Author -->
<div class="author">
  

  
  

  

    Jianxuan
        Huang, 

    Baoyao
        Yang, 

    <strong>Kejing
        Yin</strong>, 

    and Jingwen
        Xu
</div>

<!-- Journal/Book title and date -->







<div class="periodical">
  <em>IEEE Journal of Biomedical and Health Informatics</em>,  2024
</div>


    
    

    <!-- Publication Badges -->
    
      
      
      
      
      
    

    <!-- Links/Buttons -->
    <div class="links">
    
    <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    <a href="https://ieeexplore.ieee.org/document/10510586" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Publisher</a>
    
    
    
    
    
    
    <a href="https://github.com/Nekumiya-x/DNA-T" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
    
    
    
    
    
</div>

  
    <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p>The real-world Electronic Health Records (EHRs) present irregularities due to changes in the patient’s health status, resulting in various time intervals between observations and different physiological variables examined at each observation point. There have been recent applications of Transformer-based models in the field of irregular time series. However, the full attention mechanism in Transformer overly focuses on distant information, ignoring the short-term correlations of the condition. Thereby, the model is not able to capture localized changes or short-term fluctuations in patients’ conditions. Therefore, we propose a novel end-to-end Deformable Neighborhood Attention Transformer (DNA-T) for irregular medical time series. The DNA-T captures local features by dynamically adjusting the receptive field of attention and aggregating relevant deformable neighborhoods in irregular time series. Specifically, we design a Deformable Neighborhood Attention (DNA) module that enables the network to attend to relevant neighborhoods by drifting the receiving field of neighborhood attention. The DNA enhances the model’s sensitivity to local information and representation of local features, thereby capturing the correlation of localized changes in patients’ conditions. We conduct extensive experiments to validate the effectiveness of DNA-T, outperforming existing state-of-the-art methods in predicting the mortality risk of patients. Moreover, we visualize an example to validate the effectiveness of the proposed DNA. Our code is available at https://github.com/Nekumiya-x/DNA-T.</p>
    </div>
  

  
    <!-- Hidden bibtex block -->
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">huang2024dna</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{DNA-T}: Deformable Neighborhood Attention Transformer for Irregular Medical Time Series}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Huang, Jianxuan and Yang, Baoyao and Yin, Kejing and Xu, Jingwen}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Journal of Biomedical and Health Informatics}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/JBHI.2024.3395446}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
    </div>
  

  



  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100">IEEE TKDE</abbr>
        
      
      
        
          
          

<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/tkde24_patnet-480.webp 480w,/assets/img/publication_preview/tkde24_patnet-800.webp 800w,/assets/img/publication_preview/tkde24_patnet-1400.webp 1400w," sizes="200px" type="image/webp"></source>
    
    <img src="/assets/img/publication_preview/tkde24_patnet.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="tkde24_patnet.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

  
</figure>

        
      
    </div>
  

  <!-- Entry bib key -->
  <div id="yin2024patnet" class="col-sm-8">

    <!-- Title -->
<div class="title">PATNet: Propensity-Adjusted Temporal Network for Joint Imputation and Prediction Using Binary EHRs With Observation Bias</div>
<!-- Author -->
<div class="author">
  

  
  

  

    <strong>Kejing
        Yin</strong><sup><i class="fa-regular fa-envelope"></i></sup>, 

    Dong
        Qian, 

    and William K
        Cheung
</div>

<!-- Journal/Book title and date -->







<div class="periodical">
  <em>IEEE Transactions on Knowledge and Data Engineering</em>,  2024
</div>


    
    

    <!-- Publication Badges -->
    
      
      
      
      
      
        <div class="badges">
          
          
          
        </div>
      
    

    <!-- Links/Buttons -->
    <div class="links">
    
    <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    <a href="https://ieeexplore.ieee.org/document/10285044" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Publisher</a>
    
    
    
        <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=10285044" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
    
    
    
    
    
    
    
    
    
    
</div>

  
    <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p>Predictive analysis of electronic health records (EHR) is a fundamental task that could provide actionable insights to help clinicians improve the efficiency and quality of care. EHR are commonly recorded in binary format and contain inevitable missing data. The nature of missingness may vary by patients, clinical features, and time, which incurs observation bias. It is essential to account for the binary missingness and observation bias or the predictive performance could be substantially compromised. In this paper, we develop a propensity-adjusted temporal network (PATNet) to conduct data imputation and predictive analysis simultaneously. PATNet contains three subnetworks: 1) an imputation subnetwork that generates the initial imputation based on historical observations, 2) a propensity subnetwork that infers the patient-, feature-, and time-dependent propensity scores, and 3) a prediction subnetwork that produces the missing-informative prediction using the propensity-adjusted imputations and the missing probabilities. To allow the propensity scores to be inferred from data, we use the expectation-maximization (EM) algorithm to learn the imputation and propensity subnetworks and incorporate a low-rank constraint via PARAFAC2 approximation. Extensive evaluation using the MIMIC-III and eICU datasets demonstrates that PATNet outperforms the state-of-the-art methods in terms of binary data imputation, disease progression modeling, and mortality prediction tasks.</p>
    </div>
  

  
    <!-- Hidden bibtex block -->
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">yin2024patnet</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{PATNet: Propensity-Adjusted Temporal Network for Joint Imputation and Prediction Using Binary EHRs With Observation Bias}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yin, Kejing and Qian, Dong and Cheung, William K}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Knowledge and Data Engineering}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
    </div>
  

  



  </div>
</div>
</li>
</ol>
<h2 class="bibliography">2023</h2>
<ol class="bibliography"><li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100">ACM TIST</abbr>
        
      
      
        
          
          

<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/tist23_ontologies-480.webp 480w,/assets/img/publication_preview/tist23_ontologies-800.webp 800w,/assets/img/publication_preview/tist23_ontologies-1400.webp 1400w," sizes="200px" type="image/webp"></source>
    
    <img src="/assets/img/publication_preview/tist23_ontologies.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="tist23_ontologies.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

  
</figure>

        
      
    </div>
  

  <!-- Entry bib key -->
  <div id="cheong2023adaptive" class="col-sm-8">

    <!-- Title -->
<div class="title">Adaptive Integration of Categorical and Multi-relational Ontologies with EHR Data for Medical Concept Embedding</div>
<!-- Author -->
<div class="author">
  

  
  

  

    Chin Wang
        Cheong, 

    <strong>Kejing
        Yin</strong>, 

    William K
        Cheung, 

    Benjamin CM
        Fung, 

    and Jonathan
        Poon
</div>

<!-- Journal/Book title and date -->







<div class="periodical">
  <em>ACM Transactions on Intelligent Systems and Technology</em>,  2023
</div>


    
    

    <!-- Publication Badges -->
    
      
      
      
      
      
        <div class="badges">
          
          
          
        </div>
      
    

    <!-- Links/Buttons -->
    <div class="links">
    
    <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    <a href="https://dl.acm.org/doi/10.1145/3625224" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Publisher</a>
    
    
    
    
    
    
    
    
    
    
</div>

  
    <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p>Representation learning has been applied to Electronic Health Records (EHR) for medical concept embedding and the downstream predictive analytics tasks with promising results. Medical ontologies can also be integrated to guide the learning so the embedding space can better align with existing medical knowledge. Yet, properly carrying out the integration is non-trivial. Medical concepts that are similar according to a medical ontology may not be necessarily close in the embedding space learned from the EHR data, as medical ontologies organize medical concepts for their own specific objectives. Any integration methodology without considering the underlying inconsistency will result in sub-optimal medical concept embedding and, in turn, degrade the performance of the downstream tasks. In this article, we propose a novel representation learning framework called ADORE (ADaptive Ontological REpresentations) that allows the medical ontologies to adapt their structures for more robust integrating with the EHR data. ADORE first learns multiple embeddings for each category in the ontology via an attention mechanism. At the same time, it supports an adaptive integration of categorical and multi-relational ontologies in the embedding space using a category-aware graph attention network. We evaluate the performance of ADORE on a number of predictive analytics tasks using two EHR datasets. Our experimental results show that the medical concept embeddings obtained by ADORE can outperform the state-of-the-art methods for all the tasks. More importantly, it can result in clinically meaningful sub-categorization of the existing ontological categories and yield attention values that can further enhance the model interpretability.</p>
    </div>
  

  
    <!-- Hidden bibtex block -->
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">cheong2023adaptive</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Adaptive Integration of Categorical and Multi-relational Ontologies with EHR Data for Medical Concept Embedding}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Cheong, Chin Wang and Yin, Kejing and Cheung, William K and Fung, Benjamin CM and Poon, Jonathan}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{ACM Transactions on Intelligent Systems and Technology}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{14}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{6}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1--20}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{ACM New York, NY}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
    </div>
  

  



  </div>
</div>
</li></ol>
<h2 class="bibliography">2022</h2>
<ol class="bibliography"><li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100">IEEE TKDE</abbr>
        
      
      
        
          
          

<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/tkde22_chitf-480.webp 480w,/assets/img/publication_preview/tkde22_chitf-800.webp 800w,/assets/img/publication_preview/tkde22_chitf-1400.webp 1400w," sizes="200px" type="image/webp"></source>
    
    <img src="/assets/img/publication_preview/tkde22_chitf.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="tkde22_chitf.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

  
</figure>

        
      
    </div>
  

  <!-- Entry bib key -->
  <div id="yin2022learning" class="col-sm-8">

    <!-- Title -->
<div class="title">Learning Inter-Modal Correspondence and Phenotypes From Multi-Modal Electronic Health Records</div>
<!-- Author -->
<div class="author">
  

  
  

  

    <strong>Kejing
        Yin</strong><sup><i class="fa-regular fa-envelope"></i></sup>, 

    William K
        Cheung, 

    Benjamin CM
        Fung, 

    and Jonathan
        Poon
</div>

<!-- Journal/Book title and date -->







<div class="periodical">
  <em>IEEE Transactions on Knowledge and Data Engineering</em>,  2022
</div>


    
    

    <!-- Publication Badges -->
    
      
      
      
      
      
        <div class="badges">
          
          
          
        </div>
      
    

    <!-- Links/Buttons -->
    <div class="links">
    
    <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    <a href="https://ieeexplore.ieee.org/document/9261129" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Publisher</a>
    
    
    
        <a href="https://arxiv.org/pdf/2011.06301.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
    
    
    
    
    
    
    <a href="https://github.com/jakeykj/cHITF" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
    
    
    
    
    
</div>

  
    <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p>Non-negative tensor factorization has been shown a practical solution to automatically discover phenotypes from the electronic health records (EHR) with minimal human supervision. Such methods generally require an input tensor describing the inter-modal interactions to be pre-established; however, the correspondence between different modalities (e.g., correspondence between medications and diagnoses) can often be missing in practice. Although heuristic methods can be applied to estimate them, they inevitably introduce errors, and leads to sub-optimal phenotype quality. This is particularly important for patients with complex health conditions (e.g., in critical care) as multiple diagnoses and medications are simultaneously present in the records. To alleviate this problem and discover phenotypes from EHR with unobserved inter-modal correspondence, we propose the collective hidden interaction tensor factorization (cHITF) to infer the correspondence between multiple modalities jointly with the phenotype discovery. We assume that the observed matrix for each modality is marginalization of the unobserved inter-modal correspondence, which are reconstructed by maximizing the likelihood of the observed matrices. Extensive experiments conducted on the real-world MIMIC-III dataset demonstrate that cHITF effectively infers clinically meaningful inter-modal correspondence, discovers phenotypes that are more clinically relevant and diverse, and achieves better predictive performance compared with a number of state-of-the-art computational phenotyping models.</p>
    </div>
  

  
    <!-- Hidden bibtex block -->
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">yin2022learning</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Learning Inter-Modal Correspondence and Phenotypes From Multi-Modal Electronic Health Records}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yin, Kejing and Cheung, William K and Fung, Benjamin CM and Poon, Jonathan}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Knowledge and Data Engineering}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{34}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{09}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{4328--4341}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IEEE Computer Society}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
    </div>
  

  



  </div>
</div>
</li></ol>
<h2 class="bibliography">2021</h2>
<ol class="bibliography">
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100">AAAI-21</abbr>
        
      
      
        
          
          

<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/aaai21_swift-480.webp 480w,/assets/img/publication_preview/aaai21_swift-800.webp 800w,/assets/img/publication_preview/aaai21_swift-1400.webp 1400w," sizes="200px" type="image/webp"></source>
    
    <img src="/assets/img/publication_preview/aaai21_swift.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="aaai21_swift.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

  
</figure>

        
      
    </div>
  

  <!-- Entry bib key -->
  <div id="afshar2021swift" class="col-sm-8">

    <!-- Title -->
<div class="title">SWIFT: Scalable Wasserstein factorization for sparse nonnegative tensors</div>
<!-- Author -->
<div class="author">
  

  
  

  

    Ardavan
        Afshar, 

    <strong>Kejing
        Yin</strong>, 

    Sherry
        Yan, 

    Cheng
        Qian, 

    Joyce
        Ho, 

    Haesun
        Park, 

    and Jimeng
        Sun
</div>

<!-- Journal/Book title and date -->







<div class="periodical">
  <em>In Proceedings of the AAAI Conference on Artificial Intelligence</em> ,  2021
</div>


    
    
      <div class="periodical" style="color:Gray ; font-size: 0.9rem; margin-bottom: 0;">
        <i class="fa-regular fa-hand-point-right"></i> Acceptance ratio: 1692⁄7911 = 21.4%
      </div>
    

    <!-- Publication Badges -->
    
      
      
      
      
      
        <div class="badges">
          
          
          
        </div>
      
    

    <!-- Links/Buttons -->
    <div class="links">
    
    <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    <a href="https://ojs.aaai.org/index.php/AAAI/article/view/16811" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Publisher</a>
    
    
    
        <a href="https://arxiv.org/pdf/2010.04081.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
    
    
    
    
    
    
    <a href="/publications/2021_AAAI_SWIFT_codes.zip" class="btn btn-sm z-depth-0" role="button">Code</a>
    
    
    
    
    
</div>

  
    <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p>Existing tensor factorization methods assume that the input tensor follows some specific distribution (i.e. Poisson, Bernoulli, and Gaussian), and solve the factorization by minimizing some empirical loss functions defined based on the corresponding distribution. However, it suffers from several drawbacks: 1) In reality, the underlying distributions are complicated and unknown, making it infeasible to be approximated by a simple distribution. 2) The correlation across dimensions of the input tensor is not well utilized, leading to sub-optimal performance. Although heuristics were proposed to incorporate such correlation as side information under Gaussian distribution, they can not easily be generalized to other distributions. Thus, a more principled way of utilizing the correlation in tensor factorization models is still an open challenge. Without assuming any explicit distribution, we formulate the tensor factorization as an optimal transport problem with Wasserstein distance, which can handle non-negative inputs. We introduce SWIFT, which minimizes the Wasserstein distance that measures the distance between the input tensor and that of the reconstruction. In particular, we define the N-th order tensor Wasserstein loss for the widely used tensor CP factorization and derive the optimization algorithm that minimizes it. By leveraging sparsity structure and different equivalent formulations for optimizing computational efficiency, SWIFT is as scalable as other well-known CP algorithms. Using the factor matrices as features, SWIFT achieves up to 9.65% and 11.31% relative improvement over baselines for downstream prediction tasks. Under the noisy conditions, SWIFT achieves up to 15% and 17% relative improvements over the best competitors for the prediction tasks.</p>
    </div>
  

  
    <!-- Hidden bibtex block -->
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">afshar2021swift</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{SWIFT}: Scalable {Wasserstein} factorization for sparse nonnegative tensors}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Afshar, Ardavan and Yin, Kejing and Yan, Sherry and Qian, Cheng and Ho, Joyce and Park, Haesun and Sun, Jimeng}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the AAAI Conference on Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{35}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{8}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{6548--6556}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
    </div>
  

  



  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100">SDM-21</abbr>
        
      
      
        
          
          

<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/sdm21_tedpar-480.webp 480w,/assets/img/publication_preview/sdm21_tedpar-800.webp 800w,/assets/img/publication_preview/sdm21_tedpar-1400.webp 1400w," sizes="200px" type="image/webp"></source>
    
    <img src="/assets/img/publication_preview/sdm21_tedpar.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="sdm21_tedpar.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

  
</figure>

        
      
    </div>
  

  <!-- Entry bib key -->
  <div id="yin2021tedpar" class="col-sm-8">

    <!-- Title -->
<div class="title">TedPar: Temporally dependent PARAFAC2 factorization for phenotype-based disease progression modeling</div>
<!-- Author -->
<div class="author">
  

  
  

  

    <strong>Kejing
        Yin</strong>, 

    William K
        Cheung, 

    Benjamin CM
        Fung, 

    and Jonathan
        Poon
</div>

<!-- Journal/Book title and date -->







<div class="periodical">
  <em>In Proceedings of the 2021 SIAM International Conference on Data Mining (SDM)</em> ,  2021
</div>


    
    
      <div class="periodical" style="color:Gray ; font-size: 0.9rem; margin-bottom: 0;">
        <i class="fa-regular fa-hand-point-right"></i> Acceptance ratio: 85⁄400 = 21.25%
      </div>
    

    <!-- Publication Badges -->
    
      
      
      
      
      
        <div class="badges">
          
          
          
        </div>
      
    

    <!-- Links/Buttons -->
    <div class="links">
    
    <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    <a href="https://epubs.siam.org/doi/abs/10.1137/1.9781611976700.67" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Publisher</a>
    
    
    
        <a href="https://epubs.siam.org/doi/pdf/10.1137/1.9781611976700.67" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
    
    
    
    
    
    
    
    
    
    
</div>

  
    <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p>PARAFAC2 factorization provides a practical solution to map the temporally irregular electronic health records (EHR) to clinically relevant and interpretable phenotypes. Existing methods ignore the effect of interdependency of diseases over clinical history. Consequently, the crucial temporal information contained in the EHR data cannot be fully utilized and the learned phenotypes can be sub-optimal to characterize patients with progressive conditions. To address this issue, we propose a novel temporally dependent PARAFAC2 (TedPar) factorization in which the temporal dependency among the phenotypes is explicitly modeled. TedPar learns a set of target phenotypes to capture the clinical features relevant to the diseases of interest and a set of background phenotypes to capture irrelevant but frequently co-occurring clinical features. By effectively modeling the temporal dependency and separating relevant and irrelevant features, the discovered target phenotypes can be used to model the progression of the diseases of interest. Empirical evaluations show that TedPar obtains up to 32.4% relative improvement in reconstruction accuracy over the test set, suggesting significantly better generalizability than the baselines for both noise-free and heavily noisy input data. Qualitative analysis also shows that TedPar is capable of discovering clinically meaningful phenotypes and capturing the temporal dependency between them.</p>
    </div>
  

  
    <!-- Hidden bibtex block -->
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">yin2021tedpar</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{TedPar}: Temporally dependent {PARAFAC2} factorization for phenotype-based disease progression modeling}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yin, Kejing and Cheung, William K and Fung, Benjamin CM and Poon, Jonathan}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 2021 SIAM International Conference on Data Mining (SDM)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{594--602}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{Society for Industrial and Applied Mathematics}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
    </div>
  

  



  </div>
</div>
</li>
</ol>
<h2 class="bibliography">2020</h2>
<ol class="bibliography">
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100">KDD-20</abbr>
        
      
      
        
          
          

<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/kdd20_logpar-480.webp 480w,/assets/img/publication_preview/kdd20_logpar-800.webp 800w,/assets/img/publication_preview/kdd20_logpar-1400.webp 1400w," sizes="200px" type="image/webp"></source>
    
    <img src="/assets/img/publication_preview/kdd20_logpar.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="kdd20_logpar.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

  
</figure>

        
      
    </div>
  

  <!-- Entry bib key -->
  <div id="yin2020logpar" class="col-sm-8">

    <!-- Title -->
<div class="title">LogPar: Logistic PARAFAC2 factorization for temporal binary data with missing values</div>
<!-- Author -->
<div class="author">
  

  
  

  

    <strong>Kejing
        Yin</strong>, 

    Ardavan
        Afshar, 

    Joyce C
        Ho, 

    William K
        Cheung, 

    Chao
        Zhang, 

    and Jimeng
        Sun
</div>

<!-- Journal/Book title and date -->







<div class="periodical">
  <em>In Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</em> ,  2020
</div>


    
    
      <div class="periodical" style="color:Gray ; font-size: 0.9rem; margin-bottom: 0;">
        <i class="fa-regular fa-hand-point-right"></i> Research Track; acceptance ratio: 216⁄1279 = 16.9%
      </div>
    

    <!-- Publication Badges -->
    
      
      
      
      
      
        <div class="badges">
          
          
          
        </div>
      
    

    <!-- Links/Buttons -->
    <div class="links">
    
    <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    <a href="https://dl.acm.org/doi/10.1145/3394486.3403213" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Publisher</a>
    
    
    
        <a href="/publications/2020_KDD_LogPar.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
    
    
    
    
    
    
    <a href="https://github.com/jakeykj/LogPar" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
    
    
    
    
    
</div>

  
    <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p>Binary data with one-class missing values are ubiquitous in real-world applications. They can be represented by irregular tensors with varying sizes in one dimension, where value one means presence of a feature while zero means unknown (i.e., either presence or absence of a feature). Learning accurate low-rank approximations from such binary irregular tensors is a challenging task. However, none of the existing models developed for factorizing irregular tensors take the missing values into account, and they assume Gaussian distributions, resulting in a distribution mismatch when applied to binary data. In this paper, we propose Logistic PARAFAC2 (LogPar) by modeling the binary irregular tensor with Bernoulli distribution parameterized by an underlying real-valued tensor. Then we approximate the underlying tensor with a positive-unlabeled learning loss function to account for the missing values. We also incorporate uniqueness and temporal smoothness regularization to enhance the interpretability. Extensive experiments using large-scale real-world datasets show that LogPar outperforms all baselines in both irregular tensor completion and downstream predictive tasks. For the irregular tensor completion, LogPar achieves up to 26% relative improvement compared to the best baseline. Besides, LogPar obtains relative improvement of 13.2% for heart failure prediction and 14% for mortality prediction on average compared to the state-of-the-art PARAFAC2 models.</p>
    </div>
  

  
    <!-- Hidden bibtex block -->
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">yin2020logpar</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{LogPar: Logistic PARAFAC2 factorization for temporal binary data with missing values}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yin, Kejing and Afshar, Ardavan and Ho, Joyce C and Cheung, William K and Zhang, Chao and Sun, Jimeng}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery \&amp; Data Mining}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1625--1635}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
    </div>
  

  



  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100">JHIR</abbr>
        
      
      
        
          
          

<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/jhir20_catsi-480.webp 480w,/assets/img/publication_preview/jhir20_catsi-800.webp 800w,/assets/img/publication_preview/jhir20_catsi-1400.webp 1400w," sizes="200px" type="image/webp"></source>
    
    <img src="/assets/img/publication_preview/jhir20_catsi.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="jhir20_catsi.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

  
</figure>

        
      
    </div>
  

  <!-- Entry bib key -->
  <div id="yin2020context" class="col-sm-8">

    <!-- Title -->
<div class="title">Context-aware time series imputation for multi-analyte clinical data</div>
<!-- Author -->
<div class="author">
  

  
  

  

    <strong>Kejing
        Yin</strong>, 

    Liaoliao
        Feng, 

    and William K
        Cheung
</div>

<!-- Journal/Book title and date -->







<div class="periodical">
  <em>Journal of Healthcare Informatics Research</em>,  2020
</div>


    
    
      <div class="periodical" style="color:Gray ; font-size: 0.9rem; margin-bottom: 0;">
        <i class="fa-regular fa-hand-point-right"></i> This is an extension of our previous two-page abstract appeared in ICHI-19.
      </div>
    

    <!-- Publication Badges -->
    
      
      
      
      
      
        <div class="badges">
          
          
          
        </div>
      
    

    <!-- Links/Buttons -->
    <div class="links">
    
    <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    <a href="http://dx.doi.org/10.1007/s41666-020-00075-3" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Publisher</a>
    
    
    
        <a href="/publications/2020_JHIR_CATSI_AAM.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
    
    
    
    
    
    
    <a href="https://github.com/cscihkbu/CATSI" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
    
    
    
    
    
    <a href="https://archive.physionet.org/physiotools/mimic-code/ichi-2019-shared-task-challenge/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Dataset</a>
    
</div>

  
    <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p>Clinical time series imputation is recognized as an essential task in clinical data analytics. Most models rely either on strong assumptions regarding the underlying data-generation process or on preservation of only local properties without effective consideration of global dependencies. To advance the state of the art in clinical time series imputation, we participated in the 2019 ICHI Data Analytics Challenge on Missing Data Imputation (DACMI). In this paper, we present our proposed model: Context-Aware Time Series Imputation (CATSI), a novel framework based on a bidirectional LSTM in which patients’ health states are explicitly captured by learning a “global context vector” from the entire clinical time series. The imputations are then produced with reference to the global context vector. We also incorporate a cross-feature imputation component to explore the complex feature correlations. Empirical evaluations demonstrate that CATSI obtains a normalized root mean square deviation (nRMSD) of 0.1998, which is 10.6% better than that of state-of-the-art models. Further experiments on consecutive missing datasets also illustrate the effectiveness of incorporating the global context in the generation of accurate imputations.</p>
    </div>
  

  
    <!-- Hidden bibtex block -->
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">yin2020context</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Context-aware time series imputation for multi-analyte clinical data}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yin, Kejing and Feng, Liaoliao and Cheung, William K}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Journal of Healthcare Informatics Research}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{4}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{411--426}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer International Publishing}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
    </div>
  

  



  </div>
</div>
</li>
</ol>
<h2 class="bibliography">2019</h2>
<ol class="bibliography">
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100">AAAI-19</abbr>
        
      
      
        
          
          

<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/aaai19_cntf-480.webp 480w,/assets/img/publication_preview/aaai19_cntf-800.webp 800w,/assets/img/publication_preview/aaai19_cntf-1400.webp 1400w," sizes="200px" type="image/webp"></source>
    
    <img src="/assets/img/publication_preview/aaai19_cntf.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="aaai19_cntf.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

  
</figure>

        
      
    </div>
  

  <!-- Entry bib key -->
  <div id="yin2019learning" class="col-sm-8">

    <!-- Title -->
<div class="title">Learning phenotypes and dynamic patient representations via RNN regularized collective non-negative tensor factorization</div>
<!-- Author -->
<div class="author">
  

  
  

  

    <strong>Kejing
        Yin</strong>, 

    Dong
        Qian, 

    William K
        Cheung, 

    Benjamin CM
        Fung, 

    and Jonathan
        Poon
</div>

<!-- Journal/Book title and date -->







<div class="periodical">
  <em>In Proceedings of the AAAI Conference on Artificial Intelligence</em> ,  2019
</div>


    
    
      <div class="periodical" style="color:Gray ; font-size: 0.9rem; margin-bottom: 0;">
        <i class="fa-regular fa-hand-point-right"></i> Acceptance ratio: 1150⁄7095 = 16.2%
      </div>
    

    <!-- Publication Badges -->
    
      
      
      
      
      
        <div class="badges">
          
          
          
        </div>
      
    

    <!-- Links/Buttons -->
    <div class="links">
    
    <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    <a href="https://ojs.aaai.org/index.php/AAAI/article/view/3920" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Publisher</a>
    
    
    
        <a href="/publications/2019_AAAI_CNTF.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
    
    
    
    
    
    
    <a href="https://github.com/jakeykj/cntf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
    
    
    
    
    
</div>

  
    <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p>Non-negative Tensor Factorization (NTF) has been shown effective to discover clinically relevant and interpretable phenotypes from Electronic Health Records (EHR). Existing NTF based computational phenotyping models aggregate data over the observation window, resulting in the learned phenotypes being mixtures of disease states appearing at different times. We argue that by separating the clinical events happening at different times in the input tensor, the temporal dynamics and the disease progression within the observation window could be modeled and the learned phenotypes will correspond to more specific disease states. Yet how to construct the tensor for data samples with different temporal lengths and properly capture the temporal relationship specific to each individual data sample remains an open challenge. In this paper, we propose a novel Collective Non-negative Tensor Factorization (CNTF) model where each patient is represented by a temporal tensor, and all of the temporal tensors are factorized collectively with the phenotype definitions being shared across all patients. The proposed CNTF model is also flexible to incorporate non-temporal data modality and RNN-based temporal regularization. We validate the proposed model using MIMIC-III dataset, and the empirical results show that the learned phenotypes are clinically interpretable. Moreover, the proposed CNTF model outperforms the state-of-the-art computational phenotyping models for the mortality prediction task.</p>
    </div>
  

  
    <!-- Hidden bibtex block -->
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">yin2019learning</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Learning phenotypes and dynamic patient representations via RNN regularized collective non-negative tensor factorization}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yin, Kejing and Qian, Dong and Cheung, William K and Fung, Benjamin CM and Poon, Jonathan}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the AAAI Conference on Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{33}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{01}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1246--1253}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
    </div>
  

  



  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100">IJCAI-19</abbr>
        
      
      
        
          
          

<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/ijcai19_mmore-480.webp 480w,/assets/img/publication_preview/ijcai19_mmore-800.webp 800w,/assets/img/publication_preview/ijcai19_mmore-1400.webp 1400w," sizes="200px" type="image/webp"></source>
    
    <img src="/assets/img/publication_preview/ijcai19_mmore.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="ijcai19_mmore.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

  
</figure>

        
      
    </div>
  

  <!-- Entry bib key -->
  <div id="song2019medical" class="col-sm-8">

    <!-- Title -->
<div class="title">Medical Concept Embedding with Multiple Ontological Representations</div>
<!-- Author -->
<div class="author">
  

  
  

  

    Lihong
        Song, 

    Chin Wang
        Cheong, 

    <strong>Kejing
        Yin</strong>, 

    William K
        Cheung, 

    Benjamin C M
        Fung, 

    and Jonathan
        Poon
</div>

<!-- Journal/Book title and date -->







<div class="periodical">
  <em>In Proceedings of the 28th International Joint Conference on Artificial Intelligence</em> ,  2019
</div>


    
    
      <div class="periodical" style="color:Gray ; font-size: 0.9rem; margin-bottom: 0;">
        <i class="fa-regular fa-hand-point-right"></i> Acceptance ratio: 850⁄4752 = 17.9%
      </div>
    

    <!-- Publication Badges -->
    
      
      
      
      
      
        <div class="badges">
          
          
          
        </div>
      
    

    <!-- Links/Buttons -->
    <div class="links">
    
    <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    <a href="https://www.ijcai.org/proceedings/2019/641" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Publisher</a>
    
    
    
        <a href="/publications/2019_IJCAI_MMORE.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
    
    
    
    
    
    
    <a href="https://github.com/cscihkbu/mmore" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
    
    
    
    
    
</div>

  
    <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p>Learning representations of medical concepts from the Electronic Health Records (EHR) has been shown effective for predictive analytics in healthcare. Incorporation of medical ontologies has also been explored to further enhance the accuracy and to ensure better alignment with the known medical knowledge. Most of the existing work assumes that medical concepts under the same ontological category should share similar representations, which however does not always hold. In particular, the categorizations in medical ontologies were established with various factors being considered. Medical concepts even under the same ontological category may not follow similar occurrence patterns in the EHR data, leading to contradicting objectives for the representation learning. In this paper, we propose a deep learning model called MMORE which alleviates this conflicting objective issue by allowing multiple representations to be inferred for each ontological category via an attention mechanism. We apply MMORE to diagnosis prediction and our experimental results show that the representations obtained by MMORE can achieve better predictive accuracy and result in clinically meaningful sub-categorization of the existing ontological categories.</p>
    </div>
  

  
    <!-- Hidden bibtex block -->
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">song2019medical</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.24963/ijcai.2019/641}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Medical Concept Embedding with Multiple Ontological Representations}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Song, Lihong and Cheong, Chin Wang and Yin, Kejing and Cheung, William K and Fung, Benjamin C M and Poon, Jonathan}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 28th International Joint Conference on Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{19}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{4613--4619}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
    </div>
  

  



  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100">ICHI-19</abbr>
        
      
      
    </div>
  

  <!-- Entry bib key -->
  <div id="yin2019context" class="col-sm-8">

    <!-- Title -->
<div class="title">Context-aware imputation for clinical time series</div>
<!-- Author -->
<div class="author">
  

  
  

  

    <strong>Kejing
        Yin</strong>, 

    and William K
        Cheung
</div>

<!-- Journal/Book title and date -->







<div class="periodical">
  <em>In 2019 IEEE International Conference on Healthcare Informatics (ICHI)</em> ,  2019
</div>


    
    
      <div class="periodical" style="color:Gray ; font-size: 0.9rem; margin-bottom: 0;">
        <i class="fa-regular fa-hand-point-right"></i> Challenge track; two-page abstract
      </div>
    

    <!-- Publication Badges -->
    
      
      
      
      
      
        <div class="badges">
          
          
          
        </div>
      
    

    <!-- Links/Buttons -->
    <div class="links">
    
    
    
    <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    <a href="https://ieeexplore.ieee.org/abstract/document/8904733" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Publisher</a>
    
    
    
        <a href="/publications/2019_ICHI_CATSI_abs.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
    
    
    
    
    
    
    <a href="https://github.com/cscihkbu/CATSI" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
    
    
    
    
    
</div>

  

  
    <!-- Hidden bibtex block -->
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">yin2019context</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Context-aware imputation for clinical time series}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yin, Kejing and Cheung, William K}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2019 IEEE International Conference on Healthcare Informatics (ICHI)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1--3}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{IEEE}</span>
<span class="p">}</span></code></pre></figure>
    </div>
  

  



  </div>
</div>
</li>
</ol>
<h2 class="bibliography">2018</h2>
<ol class="bibliography">
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100">IJCAI-18</abbr>
        
      
      
    </div>
  

  <!-- Entry bib key -->
  <div id="yin2018joint" class="col-sm-8">

    <!-- Title -->
<div class="title">Joint Learning of Phenotypes and Diagnosis-Medication Correspondence via Hidden Interaction Tensor Factorization.</div>
<!-- Author -->
<div class="author">
  

  
  

  

    <strong>Kejing
        Yin</strong>, 

    William K
        Cheung, 

    Yang
        Liu, 

    Benjamin C M
        Fung, 

    and Jonathan
        Poon
</div>

<!-- Journal/Book title and date -->







<div class="periodical">
  <em>In Proceedings of the 27th International Joint Conference on Artificial Intelligence</em> ,  2018
</div>


    
    
      <div class="periodical" style="color:Gray ; font-size: 0.9rem; margin-bottom: 0;">
        <i class="fa-regular fa-hand-point-right"></i> Acceptance ratio: 710⁄3470 = 20%
      </div>
    

    <!-- Publication Badges -->
    
      
      
      
      
      
        <div class="badges">
          
          
          
        </div>
      
    

    <!-- Links/Buttons -->
    <div class="links">
    
    <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    <a href="https://www.ijcai.org/proceedings/2018/504" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Publisher</a>
    
    
    
        <a href="/publications/2018_IJCAI_HITF.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
    
    
    
    
    
    
    <a href="https://github.com/jakeykj/hitf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
    
    
    
    
    
    <a href="https://archive.physionet.org/physiotools/mimic-code/ichi-2019-shared-task-challenge/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Dataset</a>
    
</div>

  
    <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p>Non-negative tensor factorization has been shown effective for discovering phenotypes from the EHR data with minimal human supervision. In most cases, an interaction tensor of the elements in the EHR (e.g., diagnoses and medications) has to be first established before the factorization can be applied. Such correspondence information however is often missing. While different heuristics can be used to estimate the missing correspondence, any errors introduced will in turn cause inaccuracy for the subsequent phenotype discovery task. This is especially true for patients with multiple diseases diagnosed (e.g., under critical care). To alleviate this limitation, we propose the hidden interaction tensor factorization (HITF) where the diagnosis-medication correspondence and the underlying phenotypes are inferred simultaneously. We formulate it under a Poisson non-negative tensor factorization framework and learn the HITF model via maximum likelihood estimation. For performance evaluation, we applied HITF to the MIMIC III dataset. Our empirical results show that both the phenotypes and the correspondence inferred are clinically meaningful. In addition, the inferred HITF model outperforms a number of state-of-the-art methods for mortality prediction.</p>
    </div>
  

  
    <!-- Hidden bibtex block -->
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">yin2018joint</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.24963/ijcai.2018/504}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Joint Learning of Phenotypes and Diagnosis-Medication Correspondence via Hidden Interaction Tensor Factorization.}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yin, Kejing and Cheung, William K and Liu, Yang and Fung, Benjamin C M and Poon, Jonathan}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 27th International Joint Conference on Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{3627--3633}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span>
<span class="p">}</span></code></pre></figure>
    </div>
  

  



  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100">JAAS</abbr>
        
      
      
    </div>
  

  <!-- Entry bib key -->
  <div id="yao2018identifying" class="col-sm-8">

    <!-- Title -->
<div class="title">Identifying laser-induced plasma emission spectra of particles in a gas–solid flow based on the standard deviation of intensity across an emission line</div>
<!-- Author -->
<div class="author">
  

  
  

  

    Shunchun
        Yao, 

    Lifeng
        Zhang, 

    <strong>Kejing
        Yin</strong>, 

    Kaijie
        Bai, 

    Jialong
        Xu, 

    Zhimin
        Lu, 

    and Jidong
        Lu
</div>

<!-- Journal/Book title and date -->







<div class="periodical">
  <em>Journal of Analytical Atomic Spectrometry</em>,  2018
</div>


    
    
      <div class="periodical" style="color:Gray ; font-size: 0.9rem; margin-bottom: 0;">
        <i class="fa-regular fa-hand-point-right"></i> This is an extension of my undergraduate final-semester project.
      </div>
    

    <!-- Publication Badges -->
    
      
      
      
      
      
    

    <!-- Links/Buttons -->
    <div class="links">
    
    
    
    <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    <a href="https://pubs.rsc.org/en/content/articlelanding/2018/ja/c8ja00194d/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Publisher</a>
    
    
    
    
    
    
    
    
    
    
</div>

  

  
    <!-- Hidden bibtex block -->
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">yao2018identifying</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1039/C8JA00194D}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Identifying laser-induced plasma emission spectra of particles in a gas--solid flow based on the standard deviation of intensity across an emission line}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yao, Shunchun and Zhang, Lifeng and Yin, Kejing and Bai, Kaijie and Xu, Jialong and Lu, Zhimin and Lu, Jidong}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Journal of Analytical Atomic Spectrometry}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{33}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{10}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1676--1682}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Royal Society of Chemistry}</span>
<span class="p">}</span></code></pre></figure>
    </div>
  

  



  </div>
</div>
</li>
</ol>
<h2 class="bibliography">2015</h2>
<ol class="bibliography"><li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100">E&amp;F</abbr>
        
      
      
    </div>
  

  <!-- Entry bib key -->
  <div id="yao2015rapidly" class="col-sm-8">

    <!-- Title -->
<div class="title">Rapidly measuring unburned carbon in fly ash using molecular CN by laser-induced breakdown spectroscopy</div>
<!-- Author -->
<div class="author">
  

  
  

  

    Shunchun
        Yao, 

    Yueliang
        Shen, 

    <strong>Kejing
        Yin</strong>, 

    Gang
        Pan, 

    and Jidong
        Lu
</div>

<!-- Journal/Book title and date -->







<div class="periodical">
  <em>Energy &amp; Fuels</em>,  2015
</div>


    
    
      <div class="periodical" style="color:Gray ; font-size: 0.9rem; margin-bottom: 0;">
        <i class="fa-regular fa-hand-point-right"></i> This is a part of my undergraduate research.
      </div>
    

    <!-- Publication Badges -->
    
      
      
      
      
      
        <div class="badges">
          
          
          
        </div>
      
    

    <!-- Links/Buttons -->
    <div class="links">
    
    
    
    <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    <a href="https://pubs.acs.org/doi/pdf/10.1021/ef502174q" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Publisher</a>
    
    
    
    
    
    
    
    
    
    
</div>

  

  
    <!-- Hidden bibtex block -->
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">yao2015rapidly</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1021/ef502174q}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Rapidly measuring unburned carbon in fly ash using molecular {CN} by laser-induced breakdown spectroscopy}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yao, Shunchun and Shen, Yueliang and Yin, Kejing and Pan, Gang and Lu, Jidong}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Energy \&amp; Fuels}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{29}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1257--1263}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2015}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{ACS Publications}</span>
<span class="p">}</span></code></pre></figure>
    </div>
  

  



  </div>
</div>
</li></ol>

</div>

  </article>

  

  
</div>

      
    </div>

    <!-- Footer -->
    
  <footer class="sticky-bottom mt-5" role="contentinfo">
    <div class="container">
      © Copyright 2025
      Kejing
      
      Yin. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme.

      
      
        Last updated: October 09, 2025.
      
    </div>
  </footer>



    <!-- JavaScripts -->
    <!-- jQuery -->
<script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
<script src="/assets/js/bootstrap.bundle.min.js"></script>
<!-- <script src="/assets/js/mdb.min.js"></script> -->
<script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    
  <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>


    

    

    

    

    

    

    

    

  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script>



<!-- Bootstrap Table -->


<!-- Load Common JS -->
<script src="/assets/js/no_defer.js?0094cc95e4c40fb1eabc889840973501"></script>
<script defer src="/assets/js/common.js?da39b660470d1ba6e6b8bf5f37070b6e"></script>
<script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script>

<!-- Jupyter Open External Links New Tab -->
<script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script>

    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>


  <script async src="https://badge.dimensions.ai/badge.js"></script>


    
  <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams',
      },
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


    


    
  <!-- Scrolling Progress Bar -->
  <script type="text/javascript">
    /*
     * This JavaScript code has been adapted from the article
     * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar,
     * published on the website https://css-tricks.com on the 7th of May, 2014.
     * Couple of changes were made to the original code to make it compatible
     * with the `al-foio` theme.
     */
    const progressBar = $('#progress');
    /*
     * We set up the bar after all elements are done loading.
     * In some cases, if the images in the page are larger than the intended
     * size they'll have on the page, they'll be resized via CSS to accomodate
     * the desired size. This mistake, however, breaks the computations as the
     * scroll size is computed as soon as the elements finish loading.
     * To account for this, a minimal delay was introduced before computing the
     * values.
     */
    window.onload = function () {
      setTimeout(progressBarSetup, 50);
    };
    /*
     * We set up the bar according to the browser.
     * If the browser supports the progress element we use that.
     * Otherwise, we resize the bar thru CSS styling
     */
    function progressBarSetup() {
      if ('max' in document.createElement('progress')) {
        initializeProgressElement();
        $(document).on('scroll', function () {
          progressBar.attr({ value: getCurrentScrollPosition() });
        });
        $(window).on('resize', initializeProgressElement);
      } else {
        resizeProgressBar();
        $(document).on('scroll', resizeProgressBar);
        $(window).on('resize', resizeProgressBar);
      }
    }
    /*
     * The vertical scroll position is the same as the number of pixels that
     * are hidden from view above the scrollable area. Thus, a value > 0 is
     * how much the user has scrolled from the top
     */
    function getCurrentScrollPosition() {
      return $(window).scrollTop();
    }

    function initializeProgressElement() {
      let navbarHeight = $('#navbar').outerHeight(true);
      $('body').css({ 'padding-top': navbarHeight });
      $('progress-container').css({ 'padding-top': navbarHeight });
      progressBar.css({ top: navbarHeight });
      progressBar.attr({
        max: getDistanceToScroll(),
        value: getCurrentScrollPosition(),
      });
    }
    /*
     * The offset between the html document height and the browser viewport
     * height will be greater than zero if vertical scroll is possible.
     * This is the distance the user can scroll
     */
    function getDistanceToScroll() {
      return $(document).height() - $(window).height();
    }

    function resizeProgressBar() {
      progressBar.css({ width: getWidthPercentage() + '%' });
    }
    // The scroll ratio equals the percentage to resize the bar
    function getWidthPercentage() {
      return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
    }
  </script>


    

    

  </body>
</html>
